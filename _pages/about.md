---
permalink: /
title: "Vibhas Kumar Vats"
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

About me
------

I am first year Ph.D. student at [Indiana University Bloomington](https://www.indiana.edu/). I work in [Computer Vision Lab](http://vision.soic.indiana.edu/) with [Prof. David Crandall](https://homes.luddy.indiana.edu/djcran/). I am majoring in [Computer Science](https://cs.indiana.edu/) with minor is Computer Science. Before joining Ph.D. program, I earned master's degree in [Data Science](https://datascience.indiana.edu/programs/residential/index.html) at Indiana University. My master's thesis is on ['Response-Based Knowledge Distillation'](https://vkvats.github.io/files/Vkvats_master_thesis.pdf). I have completed my Bachelor's degree in Electrical Engineering at National Institute of Technology, Patna [(NITP)](http://www.nitp.ac.in/php/home.php). [(Résumé)](https://vkvats.github.io/files/VibhasVats-resume-public.pdf).  

Research Interests
------

* Deep Learning - Architectural understanding and exploration 
* 3D reconstruction with DL techniques
* Image Segmentation 
* Uses of Deep Learning techniques with Case-Based Reasoning methods (DL-CBR)

Teaching
------

In spring 2022, I designed and was the instructor for the first iteration of 'Computer Vision - paper discussion section' at Indiana University. The course was designed to explore the seminal papers on different architectures of deep-learning and computer vision.  The course traced the history of development of Convolutional Neural Networks (like, LeNet, AlexNet, GoogLeNet, ResNets, Wide ResNet, Stochastic ResNet, ResNeXt, DenseNet, ConvMixer, Xception Net, etc.), Multi-layer Perceptron based networks (like, MLP Mixer, ResMLP, cycleMLP and S^2 MLP model), Transformer based Networks for vision application like, Vision Transformer, DeiT, Swin Transformer, Local ViT, CvT etc. papers) and other important architectures like SAN (self-attention Network), shift-based papers etc. The class met weekly with more than 130 students taking part in the discussion. Check the discussion schedule and slides for more details.  

[Spring 2022 discussion schedule](https://vkvats.github.io/files/B657-discussion-papers-Spring22.pdf) | [Discussion Slides](https://drive.google.com/drive/folders/1vEXb8_-DZn4HFVfo7bC_Q6CvqAJlRPCB?usp=sharing) | Videos

Publications
------
**Master's Thesis**
* Response-Based Knowledge Distillation[pdf](https://vkvats.github.io/files/Vkvats_master_thesis.pdf)

**Peer-reviewed Papers**

* Vibhas Vats, David Crandall (2021). "Controlling the Quality of Distillation in Response-Based Network Compression." AAAI-22. 1-8. [(arXiv)](https://arxiv.org/abs/2112.10047)
* VK Vats, S Rai, S De, M De (2018). "Mitigating Effect of Communication Link Failure in Smart Meter-Based Load Forecasting." Springer. 289-300. [(pdf)](https://vkvats.github.io/publication/mitigating-springer-singapore-2018)
* VK Vats, S Rai, D Bharti, Mala De. (2018). "Very Short-term, Short-Term and Mid-Term Load Forecasting for Residential Academic Institure: A Case Study." IEEE. 1-6.[(pdf)](https://vkvats.github.io/files/paper1.pdf)

Please see my [Google Scholar Profile](https://scholar.google.com/citations?user=aRoPd9gAAAAJ&hl=en&authuser=5)


**Preprints**

Preprints are available on [arXiv](https://arxiv.org/a/vats_v_1.html)


Service
------

**Conference Program Committee / Reviewer**

* International Conference on Intelligence Science (ICIS) - 2022


Fun
------
I run for fun :). Find me on Nike Run club (@Vibhas_Vats).
