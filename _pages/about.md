---
permalink: /
title: "Vibhas Kumar Vats"
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

About me
------

I am a second year Ph.D. student at [Indiana University Bloomington](https://www.indiana.edu/). I work in [Computer Vision Lab](http://vision.soic.indiana.edu/) with [Prof. David Crandall](https://homes.luddy.indiana.edu/djcran/). I am majoring in [Computer Science](https://cs.indiana.edu/) with minor in Computer Science. Before joining the Ph.D. program, I earned master's degree in [Data Science](https://datascience.indiana.edu/programs/residential/index.html) at Indiana University with a thesis on ['Response-Based Knowledge Distillation'](https://vkvats.github.io/files/Vkvats_master_thesis.pdf). I completed Bachelor's degree in Electrical Engineering at National Institute of Technology, Patna [(NITP)](http://www.nitp.ac.in/php/home.php). [(Résumé)](https://vkvats.github.io/files/VibhasVats-resume-public.pdf).  

Research Interests
------

* Deep Learning - Architectural understanding and exploration 
* 3D reconstruction with DL techniques focused on Multi-View Stereo problems
* Deep learning integration with Case-Based Reasoning methods (DL-CBR)

Teaching
------

In spring 2022, I designed and was the instructor for the first iteration of 'Computer Vision - paper discussion section' at Indiana University. The course was designed to explore the seminal papers on different architectures of deep-learning and computer vision.  The course traced the history of development of Convolutional Neural Networks (like, LeNet, AlexNet, GoogLeNet, ResNets, Wide ResNet, Stochastic ResNet, ResNeXt, DenseNet, ConvMixer, Xception Net, etc.), Multi-layer Perceptron based networks (like, MLP Mixer, ResMLP, cycleMLP and S^2 MLP model), Transformer based Networks for vision application like, Vision Transformer, DeiT, Swin Transformer, Local ViT, CvT etc. papers) and other important architectures like SAN (self-attention Network), shift-based papers etc. The class met weekly with more than 130 students taking part in the discussion. Check the discussion schedule and slides for more details.  

[Spring 2022 discussion schedule](https://vkvats.github.io/files/B657-discussion-papers-Spring22.pdf) | [Discussion Slides](https://drive.google.com/drive/folders/1vEXb8_-DZn4HFVfo7bC_Q6CvqAJlRPCB?usp=sharing) | Videos

Publications
------
**Master's Thesis**
* Response-Based Knowledge Distillation. [(pdf)](https://vkvats.github.io/files/Vkvats_master_thesis.pdf)

**Peer-reviewed Papers**

* Zachary Wilkerson, Vibhas Vats, Karan Acharya, David Leake, David Crandall, "Examining the Impact of Network Architecture on Extracted Feature Quality for CBR. [pdf](http://vision.soic.indiana.edu/papers/examining2023iccbr.pdf)
* Vibhas Vats, David Crandall (2021). "Controlling the Quality of Distillation in Response-Based Network Compression." AAAI-22. 1-8. [(arXiv)](https://arxiv.org/abs/2112.10047)
* VK Vats, S Rai, S De, M De (2018). "Mitigating Effect of Communication Link Failure in Smart Meter-Based Load Forecasting." Springer. 289-300. [(pdf)](https://vkvats.github.io/publication/mitigating-springer-singapore-2018)
* VK Vats, S Rai, D Bharti, Mala De. (2018). "Very Short-term, Short-Term and Mid-Term Load Forecasting for Residential Academic Institure: A Case Study." IEEE. 1-6. [(pdf)](https://vkvats.github.io/files/paper1.pdf)

Please see my [Google Scholar Profile](https://scholar.google.com/citations?user=aRoPd9gAAAAJ&hl=en&authuser=5)


**Preprints**

Preprints are available on [arXiv](https://arxiv.org/a/vats_v_1.html)


Service
------

**Conference Program Committee / Reviewer**

* International Conference on Intelligence Science (ICIS) - 2022


Fun
------
I run for fun :). Find me on Nike Run club (@Vibhas_Vats).
